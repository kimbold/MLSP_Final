{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLSP_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i67AvVdT5YR",
        "colab_type": "text"
      },
      "source": [
        "**References:** https://towardsdatascience.com/depth-estimation-on-camera-images-using-densenets-ac454caa893\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw0wZMDIYlHV",
        "colab_type": "text"
      },
      "source": [
        "**Install required modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ypFnttYieQ",
        "colab_type": "code",
        "outputId": "f5974689-93d0-487f-b8f9-7f15eaaccc34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "!pip install keras pillow matplotlib scikit-learn scikit-image opencv-python pydot GraphViz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.21.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: GraphViz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-FSErc-Tq96",
        "colab_type": "code",
        "outputId": "58465878-e4e9-43df-9c12-a40d4007817b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/priya-dwivedi/Deep-Learning.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Deep-Learning' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fASejeqQTxCz",
        "colab_type": "code",
        "outputId": "361b5bb0-4b79-4c58-c094-e6cb9390e2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Deep-Learning/depth_estimation"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Deep-Learning/depth_estimation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmUrUJfyMuKD",
        "colab_type": "text"
      },
      "source": [
        "**Import modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6fkuAWWIIH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "27de9eca-e45b-4704-b278-413f8e8d2d3e"
      },
      "source": [
        "from IPython.display import Image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "# Kerasa / TensorFlow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
        "from keras.models import load_model\n",
        "from layers import BilinearUpSampling2D\n",
        "from loss import depth_loss_function\n",
        "from utils import predict, load_images, display_images, evaluate\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from data import extract_zip\n",
        "from io import BytesIO\n",
        "\n",
        "#Import time module to time the cpu processing time for code execution\n",
        "import time\n",
        "# Import shutil to copy files\n",
        "import shutil"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUTKgwVoZPLU",
        "colab_type": "text"
      },
      "source": [
        "**Download nyu v2 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTtwOIZMYXcG",
        "colab_type": "code",
        "outputId": "bafc5075-e296-4274-b8e6-374daa4eb098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-26 19:16:29--  https://s3-eu-west-1.amazonaws.com/densedepth/nyu_data.zip\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.106.131\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.106.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4399138715 (4.1G) [application/zip]\n",
            "Saving to: ‘nyu_data.zip.2’\n",
            "\n",
            "nyu_data.zip.2       22%[===>                ] 945.58M  1.82MB/s    eta 9m 38s "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd86mDxuZWez",
        "colab_type": "text"
      },
      "source": [
        "**Download pre-trained weights from paper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8KNVdemYY6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsfo980FerNV",
        "colab_type": "text"
      },
      "source": [
        "**Extract downloaded nyu v2 dataset data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z27JB4d1NEaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu_test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6swqs9nd9B2",
        "colab_type": "text"
      },
      "source": [
        "**Perform PCA on test data to create new datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuBoxYVDd8I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load test data\n",
        "print('Loading test data...', end='')\n",
        "\n",
        "data = extract_zip('nyu_test.zip')\n",
        "\n",
        "rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "crop = np.load(BytesIO(data['eigen_test_crop.npy']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCpgbRU-MkBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(rgb)\n",
        "#rgbmat.shape = (rgb.size[1], rgb.size[0])\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.imshow(rgb[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Porb1UJ4mMVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate modle on baseline (unmodified images):\n",
        "!python evaluate.py --model ./nyu.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bx6wUXBW0Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_rgb1(im):\n",
        "    # I think this will be slow\n",
        "    w, h = im.shape\n",
        "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
        "    ret[:, :, 0] = im\n",
        "    ret[:, :, 1] = im\n",
        "    ret[:, :, 2] = im\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6bG0hx2g02B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create list for each transformed image, so that the list can be transformed into a numpy array later\n",
        "transformed_images_list = []\n",
        "\n",
        "# Idea: \n",
        "# 0. Run evaluation on rgb file (zip) as baseline with unmodified data\n",
        "# 0.5 store original rgb file so that original data can be read for every pca\n",
        "# 1. Extract rgb file from zip and load data\n",
        "# 2. Perform PCA with specified number of components for the data\n",
        "# 3. Store modified data as rgb file\n",
        "# 4. Zip rgb file with other two files for a new \"nyu_test.zip\" for the evaluation.py\n",
        "# 5. Run evaluation.py for performance metrics\n",
        "# 6. Go back to 2. and read the original rgb data before applying PCA, then evaluate on new data again\n",
        "\n",
        "\n",
        "for components in [60,120,240,360,480]: #30\n",
        "  print(\"Number of components:\",str(components))\n",
        "  # Iterate over all rgb images and replace \n",
        "  print(\"Modifying images...\")\n",
        "  for image_id in range(rgb.shape[0]):\n",
        "    #print(\"Image:\",image_id)\n",
        "    # Read current image\n",
        "    rgb_img = PIL.Image.fromarray(rgb[image_id])\n",
        "\n",
        "    #print(rgb_imgmat.shape)\n",
        "\n",
        "    rgb_imgmat = np.array(list(rgb_img.getdata(band=0)), float)\n",
        "    \n",
        "\n",
        "    # Reshape according to orginal image dimensions\n",
        "    rgb_imgmat.shape = (rgb_img.size[1], rgb_img.size[0])\n",
        "    \n",
        "    number_of_singular_values = components\n",
        "\n",
        "    # Singular value decomposition of image\n",
        "    U, D, V = np.linalg.svd(rgb_imgmat)\n",
        "\n",
        "    number_of_singular_values = components\n",
        "\n",
        "    if(number_of_singular_values < rgb_imgmat.shape[0]):\n",
        "      #start = time.process_time()\n",
        "      reconstimg = np.matrix(U[:, :number_of_singular_values]) * np.diag(D[:number_of_singular_values]) * np.matrix(V[:number_of_singular_values, :])\n",
        "      plt.imshow(reconstimg, cmap='gray') #\n",
        "      plt.title(\"Reconstruction with \"+ str(number_of_singular_values))\n",
        "\n",
        "      transformed_images_list.append(to_rgb1(reconstimg))\n",
        "\n",
        "  transformed_rgb = np.array(transformed_images_list)\n",
        "  #transformed_rgb = np.expand_dims(transformed_rgb, 3)\n",
        "  print(transformed_rgb.shape)\n",
        "\n",
        "  #######################################\n",
        "  # Evaluate after modification\n",
        "  #######################################\n",
        "\n",
        "  # Custom object needed for inference and training\n",
        "  custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': depth_loss_function}\n",
        "\n",
        "  # Load model into GPU / CPU\n",
        "  print('Loading model...')\n",
        "  model = load_model('nyu.h5', custom_objects=custom_objects, compile=False)\n",
        "\n",
        "\n",
        "  # Load test data\n",
        "  print('Loading test data...', end='')\n",
        "\n",
        "  rgb = transformed_rgb\n",
        "\n",
        "  print('Test data loaded.\\n')\n",
        "\n",
        "\n",
        "  start = time.time()\n",
        "  print('Testing...')\n",
        "\n",
        "  e = evaluate(model, rgb, depth, crop, batch_size=6)\n",
        "\n",
        "  print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
        "  print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
        "\n",
        "  end = time.time()\n",
        "  print('\\nTest time', end-start, 's')\n",
        "\n",
        "\n",
        "#Number of components: 30\n",
        "#Modifying images...\n",
        "#(654, 480, 640, 3)\n",
        "#Loading model...\n",
        "#Loading test data...Test data loaded.\n",
        "#\n",
        "#Testing...\n",
        "#        a1,         a2,         a3,        rel,        rms,     log_10\n",
        "#    0.2438,     0.4956,     0.7263,     0.3698,     1.4703,     0.2147\n",
        "#        a1,         a2,         a3,        rel,        rms,     log_10\n",
        "#    0.2438,     0.4956,     0.7263,     0.3698,     1.4703,     0.2147\n",
        "#\n",
        "#Test time 173.71499300003052 s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6l7WXH3PLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_rgb = np.array(transformed_images_list[0])\n",
        "new_img = to_rgb1(transformed_rgb)\n",
        "print(new_img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrw9r9sE5ltk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "plt.imshow(new_img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rTTeI1fd-uh",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaQVA3qthu3w",
        "colab_type": "text"
      },
      "source": [
        "**Visualize**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcxsmYsqeNu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python test.py --model ./nyu.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM_XRYRviO5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename=\"results.png\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMEwEKoIr5nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd Deep-Learning/depth_estimation\n",
        "!dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TazqBqq3-F8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!dir my_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X50pNVzm9HwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use('classic')\n",
        "img = Image.open('my_examples/test_IMG.jpg')\n",
        "img = np.array(img)\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuxNI8aa9Ois",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYKb8IiSk3rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use('classic')\n",
        "img = Image.open('my_examples/IMG_0186.jpg')\n",
        "# convert to numpy array\n",
        "imgmat = np.array(list(img.getdata(band=0)), float)\n",
        "print(imgmat.shape)\n",
        "# Reshape according to orginal image dimensions\n",
        "imgmat.shape = (img.size[1], img.size[0])\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55b4gJn_wPWt",
        "colab_type": "text"
      },
      "source": [
        "**Singular value decomposition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UI2mHPB_wuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create folder for results\n",
        "!mkdir \"result_folder\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNz3JMb_k4ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "U, D, V = np.linalg.svd(img) #imgmat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoKJ8JrEDxPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "folder = 'my_examples/'\n",
        "for the_file in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, the_file)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT58DLNsuU5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#number_of_singular_values = 40\n",
        "for number_of_singular_values in [2,4,8,32,64,125,250,561]:\n",
        "  start = time.process_time()\n",
        "  reconstimg = np.matrix(U[:, :number_of_singular_values]) * np.diag(D[:number_of_singular_values]) * np.matrix(V[:number_of_singular_values, :])\n",
        "  plt.imshow(reconstimg) #, cmap='gray'\n",
        "  plt.title(\"Reconstruction with \"+ str(number_of_singular_values))\n",
        "  plt.savefig('my_examples/test_IMG.jpg')\n",
        "  plt.show()\n",
        "  !python test.py --model ./nyu.h5\n",
        "  print(\"Time for execution: \",time.process_time() - start)\n",
        "  # Copy result file to designated folder\n",
        "  shutil.copy2('results.png', 'result_folder/'+'result_with_'+str(number_of_singular_values)+'_components.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-LbjiW_2XEQ",
        "colab_type": "text"
      },
      "source": [
        "**Run depth estimation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdSI-b3v0hY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python test.py --model ./nyu.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB6x4MpU2bs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=\"results.png\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayl2JuxT2sYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}